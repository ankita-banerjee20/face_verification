{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating Floder Structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Paths\n",
    "pos_path = os.path.join('Data', 'Positive')\n",
    "neg_path = os.path.join('Data', 'Negative')\n",
    "anc_path = os.path.join('Data', 'Anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Directories\n",
    "os.makedirs(pos_path)\n",
    "os.makedirs(neg_path)\n",
    "os.makedirs(anc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Negative Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving lfw images to negative directory\n",
    "for directory in os.listdir('lfw'):\n",
    "    for file in os.listdir(os.path.join('lfw', directory)):\n",
    "        source_path = os.path.join('lfw', directory, file)\n",
    "        new_path = os.path.join(neg_path, file)\n",
    "        os.replace(source_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Possitive and Anchor Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    # Cropping frames\n",
    "    frame = frame[90 : 90 + 250, 240 : 240 + 250, :]\n",
    "\n",
    "    # Collecting anchor class\n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        img_name = os.path.join(anc_path, f'{uuid.uuid1()}.jpg')\n",
    "        cv2.imwrite(img_name, frame)\n",
    "\n",
    "\n",
    "    # Collecting positive class\n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        img_name = os.path.join(pos_path, f'{uuid.uuid1()}.jpg')\n",
    "        cv2.imwrite(img_name, frame)\n",
    "\n",
    "\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading and Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Loading Image Direstories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(anc_path + '\\*.jpg').take(300)\n",
    "positive = tf.data.Dataset.list_files(pos_path + '\\*.jpg').take(300)\n",
    "negative = tf.data.Dataset.list_files(neg_path + '\\*.jpg').take(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    \n",
    "    # Read in image from file path\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    \n",
    "    # Load in the image \n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    \n",
    "    # Resizing the image \n",
    "    img = tf.image.resize(img, (105, 105))\n",
    "    # Scale the image\n",
    "    img = img / 255.0\n",
    "\n",
    "    # Return image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(input_img, validation_img, label):\n",
    "    return(preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Creating Labeled Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building dataloader pipeline\n",
    "data = data.map(preprocess_dataset)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training partition\n",
    "train_data = data.take(round(len(data) * .7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing partition\n",
    "test_data = data.skip(round(len(data) * .7))\n",
    "test_data = test_data.take(round(len(data) * .3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Building Embedding Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding(): \n",
    "    input = Input(shape = (105, 105, 3), name = 'input_image')\n",
    "    \n",
    "    # First block\n",
    "    conv1 = Conv2D(64, (10, 10), activation = 'relu')(input)\n",
    "    maxpool1 = MaxPooling2D(64, (2, 2), padding = 'same')(conv1)\n",
    "    \n",
    "    # Second block\n",
    "    conv2 = Conv2D(128, (7, 7), activation = 'relu')(maxpool1)\n",
    "    maxpool2 = MaxPooling2D(64, (2, 2), padding = 'same')(conv2)\n",
    "    \n",
    "    # Third block \n",
    "    conv3 = Conv2D(128, (4, 4), activation = 'relu')(maxpool2)\n",
    "    maxpool3 = MaxPooling2D(64, (2, 2), padding = 'same')(conv3)\n",
    "    \n",
    "    # Final embedding block\n",
    "    conv4 = Conv2D(256, (4, 4), activation = 'relu')(maxpool3)\n",
    "    flatten = Flatten()(conv4)\n",
    "    embedding = Dense(4096, activation = 'sigmoid')(flatten)\n",
    "    \n",
    "    \n",
    "    return Model(inputs = [input], outputs = embedding, name = 'embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_embedding().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Distance Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dist(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "       \n",
    "    # Similarity calculation\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Siamese Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model(): \n",
    "    \n",
    "\n",
    "    input_image = Input(name = 'input_img', shape = (105, 105, 3))\n",
    "    \n",
    "    validation_image = Input(name = 'validation_img', shape = (105, 105, 3))\n",
    "    \n",
    "    # Embedding layer\n",
    "    embedding = make_embedding()\n",
    "    input_embedding = embedding(input_image)\n",
    "    validation_embedding = embedding(validation_image)\n",
    "\n",
    "\n",
    "    # Distance components\n",
    "    siamese_layer = Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(input_embedding, validation_embedding)\n",
    "    \n",
    "    # Classification layer \n",
    "    classifier = Dense(1, activation = 'sigmoid')(distances)\n",
    "    \n",
    "    return Model(inputs = [input_image, validation_image], outputs = classifier, name = 'SiameseNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = make_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Setting Loss Function and Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Setting Up Checkpoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt = [opt], siamese_model = siamese_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Building Train Step Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    with tf.GradientTape() as tape:     \n",
    "        X = batch[:2]\n",
    "        y = batch[2]\n",
    "        \n",
    "        yhat = siamese_model(X, training = True)\n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "    print(loss)\n",
    "        \n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    \n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Building Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, EPOCHS):\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        for idx, batch in enumerate(data):\n",
    "            train_step(batch)\n",
    "            progbar.update(idx + 1)\n",
    "        \n",
    "        if epoch % 10 == 0: \n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input, test_val, y_true = test_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = siamese_model.predict([test_input, test_val])\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1 if prediction > 0.5 else 0 for prediction in y_hat ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Calculating Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Recall()\n",
    "m.update_state(y_true, y_hat)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Precision()\n",
    "m.update_state(y_true, y_hat)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Recall()\n",
    "p = Precision()\n",
    "\n",
    "for test_input, test_val, y_true in test_data.as_numpy_iterator():\n",
    "    yhat = siamese_model.predict([test_input, test_val])\n",
    "    r.update_state(y_true, yhat)\n",
    "    p.update_state(y_true, yhat) \n",
    "\n",
    "print(r.result().numpy(), p.result().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Visualizing the Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_input[0])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(test_val[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Saving the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.save('siamesemodel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Ankita Banerjee\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:188: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "siamese_model = tf.keras.models.load_model('siamesemodel.keras', custom_objects = {'Dist': Dist, 'BinaryCrossentropy': tf.losses.BinaryCrossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.predict([test_input, test_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Real Time Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8bcf4171-eb40-11ee-853b-ebf06f213632.jpg',\n",
       " '8bd4071c-eb40-11ee-a53d-ebf06f213632.jpg',\n",
       " '8bd88727-eb40-11ee-a199-ebf06f213632.jpg',\n",
       " '8be44d5a-eb40-11ee-a788-ebf06f213632.jpg',\n",
       " '8be923da-eb40-11ee-98e1-ebf06f213632.jpg',\n",
       " '8bedd9e0-eb40-11ee-98dc-ebf06f213632.jpg',\n",
       " '8bf27cc0-eb40-11ee-b384-ebf06f213632.jpg',\n",
       " '8bf735bf-eb40-11ee-8db0-ebf06f213632.jpg',\n",
       " '8bfbf1eb-eb40-11ee-aac2-ebf06f213632.jpg',\n",
       " '8c112789-eb40-11ee-b7e2-ebf06f213632.jpg',\n",
       " '8c1f6021-eb40-11ee-9fd0-ebf06f213632.jpg',\n",
       " '8c2af6ea-eb40-11ee-9d75-ebf06f213632.jpg',\n",
       " '8c40197b-eb40-11ee-be26-ebf06f213632.jpg',\n",
       " '8c57b860-eb40-11ee-88f7-ebf06f213632.jpg',\n",
       " '8c5c9c3c-eb40-11ee-baf5-ebf06f213632.jpg',\n",
       " '8c613038-eb40-11ee-acf2-ebf06f213632.jpg',\n",
       " '8c65fc5f-eb40-11ee-becc-ebf06f213632.jpg',\n",
       " '8c6ad9aa-eb40-11ee-84b3-ebf06f213632.jpg',\n",
       " '8c76856c-eb40-11ee-a790-ebf06f213632.jpg',\n",
       " '8c7b48b2-eb40-11ee-bc0a-ebf06f213632.jpg',\n",
       " '8c800651-eb40-11ee-800a-ebf06f213632.jpg',\n",
       " '8c848047-eb40-11ee-a44f-ebf06f213632.jpg',\n",
       " '8c896d5c-eb40-11ee-a69b-ebf06f213632.jpg',\n",
       " '8c8de973-eb40-11ee-93b7-ebf06f213632.jpg',\n",
       " '8c99d789-eb40-11ee-9b35-ebf06f213632.jpg',\n",
       " '8c9ed667-eb40-11ee-94bd-ebf06f213632.jpg',\n",
       " '8ca31227-eb40-11ee-8cd0-ebf06f213632.jpg',\n",
       " '8ca8177e-eb40-11ee-b684-ebf06f213632.jpg',\n",
       " '8cac7a32-eb40-11ee-af4f-ebf06f213632.jpg',\n",
       " '8cb1aaea-eb40-11ee-955f-ebf06f213632.jpg',\n",
       " '8cb60ec9-eb40-11ee-8fc2-ebf06f213632.jpg',\n",
       " '8cc21818-eb40-11ee-a3f3-ebf06f213632.jpg',\n",
       " '8cc69a3d-eb40-11ee-accf-ebf06f213632.jpg',\n",
       " '8ccbc718-eb40-11ee-bc36-ebf06f213632.jpg',\n",
       " '8cd00198-eb40-11ee-b3e8-ebf06f213632.jpg',\n",
       " '8cd4dc55-eb40-11ee-8ef2-ebf06f213632.jpg',\n",
       " '8cd96628-eb40-11ee-950e-ebf06f213632.jpg',\n",
       " '8ce52ea7-eb40-11ee-93f9-ebf06f213632.jpg',\n",
       " '8cea265d-eb40-11ee-b084-ebf06f213632.jpg',\n",
       " '8ceecd16-eb40-11ee-9ad1-ebf06f213632.jpg',\n",
       " '8cf383e9-eb40-11ee-b058-ebf06f213632.jpg',\n",
       " '8cf80c3a-eb40-11ee-bc73-ebf06f213632.jpg',\n",
       " '8cfcb90d-eb40-11ee-b973-ebf06f213632.jpg',\n",
       " '8d0d1b7e-eb40-11ee-81ab-ebf06f213632.jpg',\n",
       " '8d1b87a7-eb40-11ee-bd3b-ebf06f213632.jpg',\n",
       " '8d3a3182-eb40-11ee-b38d-ebf06f213632.jpg',\n",
       " '8d3eec57-eb40-11ee-9e2e-ebf06f213632.jpg',\n",
       " '8d5d6580-eb40-11ee-9999-ebf06f213632.jpg',\n",
       " '8d6c346f-eb40-11ee-8d96-ebf06f213632.jpg',\n",
       " '8d7c0265-eb40-11ee-b91f-ebf06f213632.jpg',\n",
       " '8d8a487f-eb40-11ee-9464-ebf06f213632.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join('application_data', 'verification_images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application_data\\verification_images\\8bcf4171-eb40-11ee-853b-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8bd4071c-eb40-11ee-a53d-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8bd88727-eb40-11ee-a199-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8be44d5a-eb40-11ee-a788-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8be923da-eb40-11ee-98e1-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8bedd9e0-eb40-11ee-98dc-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8bf27cc0-eb40-11ee-b384-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8bf735bf-eb40-11ee-8db0-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8bfbf1eb-eb40-11ee-aac2-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8c112789-eb40-11ee-b7e2-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8c1f6021-eb40-11ee-9fd0-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8c2af6ea-eb40-11ee-9d75-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8c40197b-eb40-11ee-be26-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8c57b860-eb40-11ee-88f7-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8c5c9c3c-eb40-11ee-baf5-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8c613038-eb40-11ee-acf2-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8c65fc5f-eb40-11ee-becc-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8c6ad9aa-eb40-11ee-84b3-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8c76856c-eb40-11ee-a790-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8c7b48b2-eb40-11ee-bc0a-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8c800651-eb40-11ee-800a-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8c848047-eb40-11ee-a44f-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8c896d5c-eb40-11ee-a69b-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8c8de973-eb40-11ee-93b7-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8c99d789-eb40-11ee-9b35-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8c9ed667-eb40-11ee-94bd-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8ca31227-eb40-11ee-8cd0-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8ca8177e-eb40-11ee-b684-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8cac7a32-eb40-11ee-af4f-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8cb1aaea-eb40-11ee-955f-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8cb60ec9-eb40-11ee-8fc2-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8cc21818-eb40-11ee-a3f3-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8cc69a3d-eb40-11ee-accf-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8ccbc718-eb40-11ee-bc36-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8cd00198-eb40-11ee-b3e8-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8cd4dc55-eb40-11ee-8ef2-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8cd96628-eb40-11ee-950e-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8ce52ea7-eb40-11ee-93f9-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8cea265d-eb40-11ee-b084-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8ceecd16-eb40-11ee-9ad1-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8cf383e9-eb40-11ee-b058-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8cf80c3a-eb40-11ee-bc73-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8cfcb90d-eb40-11ee-b973-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8d0d1b7e-eb40-11ee-81ab-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8d1b87a7-eb40-11ee-bd3b-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8d3a3182-eb40-11ee-b38d-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8d3eec57-eb40-11ee-9e2e-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8d5d6580-eb40-11ee-9999-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8d6c346f-eb40-11ee-8d96-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8d7c0265-eb40-11ee-b91f-ebf06f213632.jpg\n",
      "application_data\\verification_images\\8d8a487f-eb40-11ee-9464-ebf06f213632.jpg\n"
     ]
    }
   ],
   "source": [
    "for image in os.listdir(os.path.join('application_data', 'verification_images')):\n",
    "    validation_img = os.path.join('application_data', 'verification_images', image)\n",
    "    print(validation_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(model, detection_threshold, verification_threshold):\n",
    "    results = []\n",
    "    for image in os.listdir(os.path.join('application_data', 'verification_images')):\n",
    "        input_img = preprocess(os.path.join('application_data', 'input_image', 'input_image.jpg'))\n",
    "        validation_img = preprocess(os.path.join('application_data', 'verification_images', image))\n",
    "        \n",
    "        result = model.predict(list(np.expand_dims([input_img, validation_img], axis = 1)), verbose = 0)\n",
    "        results.append(result)\n",
    "    \n",
    "    detection = np.sum(np.array(results) > detection_threshold)\n",
    "    \n",
    "    verification = detection / len(os.listdir(os.path.join('application_data', 'verification_images'))) \n",
    "    verified = verification > verification_threshold\n",
    "    \n",
    "    return results, verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    frame = frame[90 : 90 + 250, 240 : 240 + 250, :]\n",
    "\n",
    "    \n",
    "    cv2.imshow('Verification', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
    "        cv2.imwrite(os.path.join('application_data', 'input_image', 'input_image.jpg'), frame)\n",
    "        results, verified = verify(siamese_model, 0.5, 0.7)\n",
    "        print(verified)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.squeeze(results) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
