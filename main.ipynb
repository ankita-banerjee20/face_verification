{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating Floder Structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Paths\n",
    "pos_path = os.path.join('Data', 'Positive')\n",
    "neg_path = os.path.join('Data', 'Negative')\n",
    "anc_path = os.path.join('Data', 'Anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Directories\n",
    "os.makedirs(pos_path)\n",
    "os.makedirs(neg_path)\n",
    "os.makedirs(anc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Negative Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving lfw images to negative directory\n",
    "for directory in os.listdir('lfw'):\n",
    "    for file in os.listdir(os.path.join('lfw', directory)):\n",
    "        source_path = os.path.join('lfw', directory, file)\n",
    "        new_path = os.path.join(neg_path, file)\n",
    "        os.replace(source_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Possitive and Anchor Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    # Cropping frames\n",
    "    frame = frame[90 : 90 + 250, 240 : 240 + 250, :]\n",
    "\n",
    "    # Collecting anchor class\n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        img_name = os.path.join(anc_path, f'{uuid.uuid1()}.jpg')\n",
    "        cv2.imwrite(img_name, frame)\n",
    "\n",
    "\n",
    "    # Collecting positive class\n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        img_name = os.path.join(pos_path, f'{uuid.uuid1()}.jpg')\n",
    "        cv2.imwrite(img_name, frame)\n",
    "\n",
    "\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading and Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Loading Image Direstories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(anc_path + '\\*.jpg').take(300)\n",
    "positive = tf.data.Dataset.list_files(pos_path + '\\*.jpg').take(300)\n",
    "negative = tf.data.Dataset.list_files(neg_path + '\\*.jpg').take(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    \n",
    "    # Read in image from file path\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    \n",
    "    # Load in the image \n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    \n",
    "    # Resizing the image \n",
    "    img = tf.image.resize(img, (105, 105))\n",
    "    # Scale the image\n",
    "    img = img / 255.0\n",
    "\n",
    "    # Return image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(input_img, validation_img, label):\n",
    "    return(preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Creating Labeled Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building dataloader pipeline\n",
    "data = data.map(preprocess_dataset)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training partition\n",
    "train_data = data.take(round(len(data) * .7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing partition\n",
    "test_data = data.skip(round(len(data) * .7))\n",
    "test_data = test_data.take(round(len(data) * .3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Building Embedding Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding(): \n",
    "    input = Input(shape = (105, 105, 3), name = 'input_image')\n",
    "    \n",
    "    # First block\n",
    "    conv1 = Conv2D(64, (10, 10), activation = 'relu')(input)\n",
    "    maxpool1 = MaxPooling2D(64, (2,2), padding = 'same')(conv1)\n",
    "    \n",
    "    # Second block\n",
    "    conv2 = Conv2D(128, (7, 7), activation = 'relu')(maxpool1)\n",
    "    maxpool2 = MaxPooling2D(64, (2,2), padding = 'same')(conv2)\n",
    "    \n",
    "    # Third block \n",
    "    conv3 = Conv2D(128, (4, 4), activation = 'relu')(maxpool2)\n",
    "    maxpool3 = MaxPooling2D(64, (2,2), padding = 'same')(conv3)\n",
    "    \n",
    "    # Final embedding block\n",
    "    conv4 = Conv2D(256, (4, 4), activation = 'relu')(maxpool3)\n",
    "    flatten = Flatten()(conv4)\n",
    "    embedding = Dense(4096, activation = 'sigmoid')(flatten)\n",
    "    \n",
    "    \n",
    "    return Model(inputs = [input], outputs = [embedding], name = 'embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_image (InputLayer)    [(None, 105, 105, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 96, 96, 64)        19264     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 48, 48, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 42, 42, 128)       401536    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 21, 21, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 18, 18, 128)       262272    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 9, 9, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 6, 6, 256)         524544    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4096)              37752832  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38960448 (148.62 MB)\n",
      "Trainable params: 38960448 (148.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "make_embedding().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Distance Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dist(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "       \n",
    "    # Similarity calculation\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### **Siamese Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model(): \n",
    "    \n",
    "\n",
    "    input_image = Input(name = 'input_img', shape = (105, 105, 3))\n",
    "    \n",
    "    validation_image = Input(name = 'validation_img', shape = (105, 105, 3))\n",
    "    \n",
    "    # Embedding layer\n",
    "    embedding = make_embedding()\n",
    "    input_embedding = embedding(input_image)\n",
    "    validation_embedding = embedding(validation_image)\n",
    "\n",
    "\n",
    "    # Distance components\n",
    "    siamese_layer = Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(input_embedding, validation_embedding)\n",
    "    \n",
    "    # Classification layer \n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    \n",
    "    return Model(inputs = [input_image, validation_image], outputs = classifier, name  ='SiameseNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = make_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_img (InputLayer)      [(None, 105, 105, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " validation_img (InputLayer  [(None, 105, 105, 3)]        0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)      (None, 4096)                 3896044   ['input_img[0][0]',           \n",
      "                                                          8          'validation_img[0][0]']      \n",
      "                                                                                                  \n",
      " distance (Dist)             (None, 4096)                 0         ['embedding[0][0]',           \n",
      "                                                                     'embedding[1][0]']           \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    4097      ['distance[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38964545 (148.64 MB)\n",
      "Trainable params: 38964545 (148.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
